{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtmIdW7ReWvXsG42nOQ+Rq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamara-kostova/MSc_Thesis_Neuroimaging/blob/master/03_data_loaders_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03 â€“ Data Loaders and Augmentation\n",
        "\n",
        "This notebook defines the PyTorch datasets, data loaders, and augmentation pipelines used for\n",
        "training and evaluating deep learning models on neuroimaging data (MRI and CT).\n",
        "\n",
        "All images have already been preprocessed in the previous step (grayscale conversion and resizing).\n",
        "Here, we focus on:\n",
        "- Dataset abstractions\n",
        "- Train/validation/test data loaders\n",
        "- Medically plausible data augmentation\n"
      ],
      "metadata": {
        "id": "bOf2XcQRzKV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/MSc_Thesis_Neuroimaging\"\n",
        "RAW_DIR = f\"{BASE_DIR}/data/raw\"\n",
        "PROC_DIR = f\"{BASE_DIR}/data/processed\"\n",
        "SPLIT_DIR = f\"{BASE_DIR}/data/split\""
      ],
      "metadata": {
        "id": "WOK8snZlzcC9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "def collect_images(class_path):\n",
        "    files = []\n",
        "    for ext in (\"*.png\", \"*.jpg\", \"*.jpeg\"):\n",
        "        files.extend(glob.glob(os.path.join(class_path, ext)))\n",
        "    return files"
      ],
      "metadata": {
        "id": "38aPxWU2zhNT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At9WlPqxzpKl",
        "outputId": "b96eb03b-a88e-4697-aba4-b85830bd65bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class\n",
        "Key design choices:\n",
        "- Images are loaded in **grayscale**, consistent with MRI and CT imaging\n",
        "- Labels are inferred from folder structure\n",
        "- Class-to-index mappings are explicit and reusable across splits\n",
        "- The same dataset class supports binary and multiclass classification tasks"
      ],
      "metadata": {
        "id": "v10-HXw3ytUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8V0z6Sqiyl_k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class NeuroImageDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None, class_to_idx=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.samples = []\n",
        "        self.class_to_idx = class_to_idx or {}\n",
        "\n",
        "        for class_name in sorted(os.listdir(data_dir)):\n",
        "            class_path = os.path.join(data_dir, class_name)\n",
        "            if not os.path.isdir(class_path):\n",
        "                continue\n",
        "\n",
        "            if class_name not in self.class_to_idx:\n",
        "                self.class_to_idx[class_name] = len(self.class_to_idx)\n",
        "\n",
        "            label = self.class_to_idx[class_name]\n",
        "\n",
        "            for img_path in collect_images(class_path):\n",
        "                self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "\n",
        "        image = np.array(Image.open(img_path).convert(\"L\"))  # grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentations\n",
        "Augmentations are carefully chosen to be **medically plausible**:\n",
        "- Small rotations to simulate patient positioning variability\n",
        "- Horizontal flips where anatomically acceptable\n",
        "- Mild intensity and noise variations to simulate scanner differences\n"
      ],
      "metadata": {
        "id": "XCWcrx6py2Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "train_aug = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=10, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.GaussNoise(p=0.15),\n",
        "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_test_aug = A.Compose([\n",
        "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "    ToTensorV2()\n",
        "])\n"
      ],
      "metadata": {
        "id": "XTQwNREvy2EL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoaders\n",
        "PyTorch `DataLoader` objects are created for each dataset split:\n",
        "- **Training**: shuffled batches\n",
        "- **Validation/Test**: deterministic order\n",
        "\n",
        "This setup ensures:\n",
        "- No information leakage between splits\n",
        "- Efficient batching and parallel data loading\n",
        "- Reproducible evaluation"
      ],
      "metadata": {
        "id": "zSqFxZfAy7Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset_paths = {\n",
        "    \"tumor_binary\": f\"{SPLIT_DIR}/MRI_tumor_binary_norm\",\n",
        "    \"stroke_binary\": f\"{SPLIT_DIR}/CT_stroke_binary_norm\"\n",
        "}\n",
        "\n",
        "for name, base_path in dataset_paths.items():\n",
        "    print(f\"\\n{name.upper()}\")\n",
        "\n",
        "    class_to_idx = None  # shared mapping across splits\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        split_path = os.path.join(base_path, split)\n",
        "\n",
        "        if not os.path.exists(split_path):\n",
        "            continue\n",
        "\n",
        "        ds = NeuroImageDataset(\n",
        "            split_path,\n",
        "            transform=train_aug if split == \"train\" else val_test_aug,\n",
        "            class_to_idx=class_to_idx\n",
        "        )\n",
        "\n",
        "        class_to_idx = ds.class_to_idx  # preserve mapping\n",
        "\n",
        "        dl = DataLoader(\n",
        "            ds,\n",
        "            batch_size=32,\n",
        "            shuffle=(split == \"train\"),\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        images, labels = next(iter(dl))\n",
        "        print(f\"{split}: images={images.shape}, labels={labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW-sY6i-y8fD",
        "outputId": "c8ad753e-5f57-4298-a1b5-7b2c9483e2d7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TUMOR_BINARY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: images=torch.Size([32, 1, 224, 224]), labels=torch.Size([32])\n",
            "val: images=torch.Size([32, 1, 224, 224]), labels=torch.Size([32])\n",
            "test: images=torch.Size([32, 1, 224, 224]), labels=torch.Size([32])\n",
            "\n",
            "STROKE_BINARY\n",
            "train: images=torch.Size([32, 1, 224, 224]), labels=torch.Size([32])\n",
            "val: images=torch.Size([32, 1, 224, 224]), labels=torch.Size([32])\n",
            "test: images=torch.Size([32, 1, 224, 224]), labels=torch.Size([32])\n"
          ]
        }
      ]
    }
  ]
}