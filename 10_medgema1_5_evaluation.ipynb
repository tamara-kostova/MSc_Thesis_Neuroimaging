{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMjiOzEiz+wXZjn4Fs7CwJC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamara-kostova/MSc_Thesis_Neuroimaging/blob/master/10_medgema1_5_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lcfu7rAJEHV",
        "outputId": "a1f84d0c-811b-4abb-8a2a-fc1707cab020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/MSc_Thesis_Neuroimaging/data/split/labels\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaRJtxISJpfM",
        "outputId": "bf4e3dfb-6873-4ce2-a8a2-56940e5f091e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CT_stroke_binary_norm_test_labels.json\n",
            "CT_stroke_binary_norm_train_labels.json\n",
            "CT_stroke_binary_norm_val_labels.json\n",
            "MRI_ms_norm_test_labels.json\n",
            "MRI_ms_norm_train_labels.json\n",
            "MRI_ms_norm_val_labels.json\n",
            "MRI_tumor_binary_norm_test_labels.json\n",
            "MRI_tumor_binary_norm_train_labels.json\n",
            "MRI_tumor_binary_norm_val_labels.json\n",
            "MRI_tumor_multiclass_norm_test_labels.json\n",
            "MRI_tumor_multiclass_norm_train_labels.json\n",
            "MRI_tumor_multiclass_norm_val_labels.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MedGemma-1.5-4B multimodal evaluation with vLLM\n",
        "\n",
        "- One inference per image\n",
        "- Resume-safe checkpoints\n",
        "- Dataset-agnostic\n",
        "- Thesis / benchmark ready\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==============================\n",
        "# CONFIG\n",
        "# ==============================\n",
        "\n",
        "VLLM_ENDPOINT = \"http://<SERVER_IP>:8000/v1/chat/completions\"\n",
        "MODEL_NAME = \"google/medgemma-1.5-4b\"\n",
        "\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/MSc_Thesis_Neuroimaging\")\n",
        "SPLIT_DIR = BASE_DIR / \"data/split\"\n",
        "LABELS_DIR = SPLIT_DIR / \"labels\"\n",
        "\n",
        "RESULTS_DIR = BASE_DIR / \"results/medgemma\"\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DATASETS = [\n",
        "    \"CT_stroke_binary_norm\",\n",
        "    \"MRI_ms_norm\",\n",
        "    \"MRI_tumor_binary_norm\",\n",
        "    \"MRI_tumor_multiclass_norm\",\n",
        "]\n",
        "\n",
        "SPLIT = \"test\"\n",
        "\n",
        "MAX_TOKENS = 256\n",
        "TEMPERATURE = 0.0\n",
        "TIMEOUT = 90\n",
        "\n",
        "# ==============================\n",
        "# PROMPT\n",
        "# ==============================\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a medical imaging expert.\n",
        "\n",
        "Analyze the provided neuroimaging scan and output a JSON object:\n",
        "\n",
        "{\n",
        "  \"diagnosis\": string or null,\n",
        "  \"subtype\": string or null,\n",
        "  \"modality\": \"CT\" | \"MRI\" | null,\n",
        "  \"sequence\": string or null,\n",
        "  \"plane\": \"Axial\" | \"Sagittal\" | \"Coronal\" | null\n",
        "}\n",
        "\n",
        "If uncertain, use null.\n",
        "Output JSON only.\n",
        "\"\"\"\n",
        "\n",
        "# ==============================\n",
        "# UTILS\n",
        "# ==============================\n",
        "\n",
        "def encode_image(image_path: Path) -> str:\n",
        "    \"\"\"Encode image as base64 PNG for vLLM.\"\"\"\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    buffer = BytesIO()\n",
        "    img.save(buffer, format=\"PNG\")\n",
        "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "def infer(image_path: Path) -> str:\n",
        "    \"\"\"Send one multimodal inference request to vLLM.\"\"\"\n",
        "    image_b64 = encode_image(image_path)\n",
        "\n",
        "    payload = {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Analyze this scan.\"},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/png;base64,{image_b64}\"\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        \"temperature\": TEMPERATURE,\n",
        "        \"max_tokens\": MAX_TOKENS,\n",
        "    }\n",
        "\n",
        "    r = requests.post(VLLM_ENDPOINT, json=payload, timeout=TIMEOUT)\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# LOAD LABELS\n",
        "# ==============================\n",
        "\n",
        "for dataset in DATASETS:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"DATASET: {dataset} [{SPLIT}]\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    labels_file = LABELS_DIR / f\"{dataset}_{SPLIT}_labels.json\"\n",
        "    image_root = SPLIT_DIR / dataset / SPLIT\n",
        "\n",
        "    if not labels_file.exists():\n",
        "        print(f\"⚠ Missing labels: {labels_file}\")\n",
        "        continue\n",
        "\n",
        "    with open(labels_file) as f:\n",
        "        labels = json.load(f)\n",
        "\n",
        "    output_file = RESULTS_DIR / f\"{dataset}_{SPLIT}_outputs.jsonl\"\n",
        "\n",
        "    processed = set()\n",
        "    if output_file.exists():\n",
        "        with open(output_file) as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    processed.add(json.loads(line)[\"image_id\"])\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    print(f\"✔ Resuming at {len(processed)} samples\")\n",
        "\n",
        "    with open(output_file, \"a\") as out:\n",
        "        for relpath, gt in tqdm(labels.items(), desc=dataset):\n",
        "            image_id = relpath.replace(\"/\", \"_\")\n",
        "\n",
        "            if image_id in processed:\n",
        "                continue\n",
        "\n",
        "            img_path = image_root / relpath\n",
        "            if not img_path.exists():\n",
        "                print(f\"⚠ Missing image: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                response = infer(img_path)\n",
        "\n",
        "                record = {\n",
        "                    \"dataset\": dataset,\n",
        "                    \"split\": SPLIT,\n",
        "                    \"image_id\": image_id,\n",
        "                    \"relpath\": relpath,\n",
        "                    \"ground_truth\": gt,\n",
        "                    \"raw_response\": response,\n",
        "                }\n",
        "\n",
        "                out.write(json.dumps(record) + \"\\n\")\n",
        "                out.flush()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error {image_id}: {e}\")\n",
        "\n",
        "print(\"\\n✅ ALL DATASETS COMPLETED\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA_hcQsfJnOv",
        "outputId": "6e389397-71bf-4f6b-d521-ad0ce9e1729a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET: CT_stroke_binary_norm [test]\n",
            "======================================================================\n",
            "✔ Resuming at 0 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CT_stroke_binary_norm:   0%|          | 1/999 [01:34<26:15:34, 94.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error _content_drive_MyDrive_MSc_Thesis_Neuroimaging_data_split_CT_stroke_binary_norm_test_normal_16347.png: HTTPConnectionPool(host='185.153.49.170', port=8000): Max retries exceeded with url: /v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f3ffcf35d90>, 'Connection to 185.153.49.170 timed out. (connect timeout=90)'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCT_stroke_binary_norm:   0%|          | 2/999 [03:05<25:35:10, 92.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error _content_drive_MyDrive_MSc_Thesis_Neuroimaging_data_split_CT_stroke_binary_norm_test_normal_12577.png: HTTPConnectionPool(host='185.153.49.170', port=8000): Max retries exceeded with url: /v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f3ffcd424e0>, 'Connection to 185.153.49.170 timed out. (connect timeout=90)'))\n"
          ]
        }
      ]
    }
  ]
}